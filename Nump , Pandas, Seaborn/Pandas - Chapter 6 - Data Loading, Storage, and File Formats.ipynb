{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Reading and Writing Data in Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  something  a   b     c    d message\n",
      "0       one  1   2   3.0  4.0     NaN\n",
      "1       two  5   6   NaN  8.0     NaN\n",
      "2     three  9  10  11.0  NaN     foo\n"
     ]
    }
   ],
   "source": [
    "# Pandas features a number of functions for reading tabular data as a DataFrame\n",
    "# object. Table 6-1 summarizes some of them, though read_csv and read_table are\n",
    "# likely the ones you’ll use the most.\n",
    "# Visit table 6-1 Python For Data Analysis By Wes Mckinney book pg # 167\n",
    "\n",
    "# Handling dates and other custom types can require extra effort. Let’s start with a small comma-separated (CSV) text file:\n",
    "\n",
    "!type ex1.csv\n",
    "\n",
    "# Since this is comma-delimited, we can use read_csv to read it into a DataFrame:\n",
    "df = pd.read_csv('ex1.csv')\n",
    "print(df)\n",
    "\n",
    "# We could also have used read_table and specified the delimiter:\n",
    "df = pd.read_table('ex1.csv',sep = ',') # or we can use delimiter both are same.\n",
    "print(df)\n",
    "\n",
    "# A file will not always have a header row. Consider this file:\n",
    "df = pd.read_csv('ex2.csv',sep = ',',header=None) # it is by default set to 'infer' which means it will pick the first row of\n",
    "# text file as column labels.\n",
    "print(df)\n",
    "# if you want to set the names of columns, you can use names parameter.\n",
    "df = pd.read_csv('ex2.csv',sep = ',',names=['a','b','c','d','e'])\n",
    "print(df)\n",
    "\n",
    "# Suppose you wanted the message column to be the index of the returned DataFrame.\n",
    "# You can either indicate you want the column at index 4 or named 'message' using\n",
    "# the index_col argument:\n",
    "df = pd.read_csv('ex1.csv',index_col=['message'])\n",
    "print(df)\n",
    "\n",
    "# In the event that you want to form a hierarchical index from multiple columns, pass a list of column numbers or names:\n",
    "# Hierarchical indexing (AKA multiindexes) , means we can use multiple columns as index of DataFrame.\n",
    "df = pd.read_csv('ex3.csv',index_col=['key1','key2']) # here we are using 'message' and 'a' columns as indexes of a DataFrame.\n",
    "print(df)\n",
    "\n",
    "# The parser functions have many additional arguments to help you handle the wide\n",
    "# variety of exception file formats that occur (see a partial listing in Table 6-2). For\n",
    "# example, you can skip the first, third, and fourth rows of a file with skiprows:\n",
    "!type ex4.csv\n",
    "df = pd.read_csv('ex4.csv',skiprows=[0,2,3])\n",
    "print(df)\n",
    "\n",
    "# Handling missing values is an important and frequently nuanced part of the file pars‐\n",
    "# ing process. Missing data is usually either not present (empty string) or marked by\n",
    "# some sentinel value. By default, pandas uses a set of commonly occurring sentinels, such as NA and NULL:\n",
    "# means while reading a file if pandas found NA or NULL in any row or any column it will set it to NaN and NA and NULL must be\n",
    "# in Capital case.\n",
    "!type ex5.csv\n",
    "df = pd.read_csv('ex5.csv')\n",
    "print(df)\n",
    "print(pd.isnull(df))\n",
    "\n",
    "# The na_values(Sequence of values to replace with NA.) option can take either a list or set of strings\n",
    "# to consider missing values:\n",
    "\n",
    "df = pd.read_csv('ex5.csv',na_values=[12,'world']) # here i have passed 12 and world that later will replace with NaN.\n",
    "print(df)\n",
    "\n",
    "# Table 6-2 lists some frequently used options in pandas.read_csv and pandas.read_table.\n",
    "# Visit table 6-2 Python For Data Analysis By Wes Mckinney book pg # 172\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Reading Text Files in Pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>...</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>...</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>...</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>...</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>...</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>...</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>220000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>El Mariachi</td>\n",
       "      <td>6.6</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>9000</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Newlyweds</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"nam...</td>\n",
       "      <td>http://www.hallmarkchannel.com/signedsealeddel...</td>\n",
       "      <td>...</td>\n",
       "      <td>Signed, Sealed, Delivered</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://shanghaicalling.com/</td>\n",
       "      <td>...</td>\n",
       "      <td>Shanghai Calling</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 99, \"name\": \"Documentary\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>My Date with Drew</td>\n",
       "      <td>6.3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4803 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         budget                                             genres  \\\n",
       "0     237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1     300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2     245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "3     250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4     260000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "...         ...                                                ...   \n",
       "4798     220000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4799       9000  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...   \n",
       "4800          0  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"nam...   \n",
       "4801          0                                                 []   \n",
       "4802          0                [{\"id\": 99, \"name\": \"Documentary\"}]   \n",
       "\n",
       "                                               homepage  ...  \\\n",
       "0                           http://www.avatarmovie.com/  ...   \n",
       "1          http://disney.go.com/disneypictures/pirates/  ...   \n",
       "2           http://www.sonypictures.com/movies/spectre/  ...   \n",
       "3                    http://www.thedarkknightrises.com/  ...   \n",
       "4                  http://movies.disney.com/john-carter  ...   \n",
       "...                                                 ...  ...   \n",
       "4798                                                NaN  ...   \n",
       "4799                                                NaN  ...   \n",
       "4800  http://www.hallmarkchannel.com/signedsealeddel...  ...   \n",
       "4801                        http://shanghaicalling.com/  ...   \n",
       "4802                                                NaN  ...   \n",
       "\n",
       "                                         title vote_average vote_count  \n",
       "0                                       Avatar          7.2      11800  \n",
       "1     Pirates of the Caribbean: At World's End          6.9       4500  \n",
       "2                                      Spectre          6.3       4466  \n",
       "3                        The Dark Knight Rises          7.6       9106  \n",
       "4                                  John Carter          6.1       2124  \n",
       "...                                        ...          ...        ...  \n",
       "4798                               El Mariachi          6.6        238  \n",
       "4799                                 Newlyweds          5.9          5  \n",
       "4800                 Signed, Sealed, Delivered          7.0          6  \n",
       "4801                          Shanghai Calling          5.7          7  \n",
       "4802                         My Date with Drew          6.3         16  \n",
       "\n",
       "[4803 rows x 20 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When processing very large files or figuring out the right set of arguments to cor‐\n",
    "# rectly process a large file, you may only want to read in a small piece of a file or iterate \n",
    "# through smaller chunks of the file.\n",
    "movie = pd.read_csv(r'Data Sets\\Movies Kaggle .csv')\n",
    "# Before we look at a large file, we make the pandas display settings more compact:\n",
    "pd.options.display.max_rows = 10 # this will set the display settings to max 10 rows(Which is by default btw). we can change \n",
    "# the value whatever we want. Also we can change the columns settings like rows.\n",
    "pd.options.display.max_columns = 6\n",
    "# Now we have:\n",
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>...</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>...</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>...</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>...</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>...</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>...</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>258000000</td>\n",
       "      <td>[{\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 28, \"na...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spider-man3/</td>\n",
       "      <td>...</td>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 16, \"name\": \"Animation\"}, {\"id\": 10751...</td>\n",
       "      <td>http://disney.go.com/disneypictures/tangled/</td>\n",
       "      <td>...</td>\n",
       "      <td>Tangled</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2  245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "3  250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4  260000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "5  258000000  [{\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 28, \"na...   \n",
       "6  260000000  [{\"id\": 16, \"name\": \"Animation\"}, {\"id\": 10751...   \n",
       "\n",
       "                                          homepage  ...  \\\n",
       "0                      http://www.avatarmovie.com/  ...   \n",
       "1     http://disney.go.com/disneypictures/pirates/  ...   \n",
       "2      http://www.sonypictures.com/movies/spectre/  ...   \n",
       "3               http://www.thedarkknightrises.com/  ...   \n",
       "4             http://movies.disney.com/john-carter  ...   \n",
       "5  http://www.sonypictures.com/movies/spider-man3/  ...   \n",
       "6     http://disney.go.com/disneypictures/tangled/  ...   \n",
       "\n",
       "                                      title vote_average vote_count  \n",
       "0                                    Avatar          7.2      11800  \n",
       "1  Pirates of the Caribbean: At World's End          6.9       4500  \n",
       "2                                   Spectre          6.3       4466  \n",
       "3                     The Dark Knight Rises          7.6       9106  \n",
       "4                               John Carter          6.1       2124  \n",
       "5                              Spider-Man 3          5.9       3576  \n",
       "6                                   Tangled          7.4       3330  \n",
       "\n",
       "[7 rows x 20 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to only read a small number of rows (avoiding reading the entire file), specify that with nrows:\n",
    "movie1 = pd.read_csv(r'Data Sets\\Movies Kaggle .csv',nrows = 7 )\n",
    "movie1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.io.parsers.TextFileReader object at 0x0000023662A13AC8>\n",
      "   Unnamed: 0         0         1         2         3\n",
      "0           0  0.469112 -0.282863 -1.509059 -1.135632\n",
      "1           1  1.212112 -0.173215  0.119209 -1.044236\n",
      "2           2 -0.861849 -2.104569 -0.494929  1.071804\n",
      "   Unnamed: 0         0         1         2         3\n",
      "3           3  0.721555 -0.706771 -1.039575  0.271860\n",
      "4           4 -0.424972  0.567020  0.276232 -1.087401\n",
      "5           5 -0.673690  0.113648 -1.478427  0.524988\n",
      "   Unnamed: 0         0         1         2         3\n",
      "6           6  0.404705  0.577046 -1.715002 -1.039268\n",
      "7           7 -0.370647 -1.157892 -1.344312  0.844885\n",
      "8           8  1.075770 -0.109050  1.643563 -1.469388\n",
      "   Unnamed: 0         0       1         2         3\n",
      "9           9  0.357021 -0.6746 -1.776904 -0.968914\n",
      "<pandas.io.parsers.TextFileReader object at 0x0000023662A13160>\n",
      "   Unnamed: 0         0         1         2         3\n",
      "0           0  0.469112 -0.282863 -1.509059 -1.135632\n",
      "1           1  1.212112 -0.173215  0.119209 -1.044236\n",
      "2           2 -0.861849 -2.104569 -0.494929  1.071804\n",
      "   Unnamed: 0         0         1         2         3\n",
      "3           3  0.721555 -0.706771 -1.039575  0.271860\n",
      "4           4 -0.424972  0.567020  0.276232 -1.087401\n",
      "5           5 -0.673690  0.113648 -1.478427  0.524988\n",
      "   Unnamed: 0         0         1         2         3\n",
      "6           6  0.404705  0.577046 -1.715002 -1.039268\n",
      "7           7 -0.370647 -1.157892 -1.344312  0.844885\n",
      "8           8  1.075770 -0.109050  1.643563 -1.469388\n",
      "   Unnamed: 0         0       1         2         3\n",
      "9           9  0.357021 -0.6746 -1.776904 -0.968914\n"
     ]
    }
   ],
   "source": [
    "# To read a file in pieces, specify a chunksize as a number of rows:\n",
    "f = pd.read_csv('Data Sets\\Chunking_Data.csv',delimiter='|',chunksize=3) # this will return text parser object which allows\n",
    "# us to iterate over the parts of the file according to the chunksize. \n",
    "# here chunksize = 3 means this will give 3 rows in first iteration and then in second iteration this will return next\n",
    "# 3 rows and so on..................................\n",
    "print(f)\n",
    "for chunk in f:\n",
    "    print(chunk)\n",
    "\n",
    "# another method to do the same is, using iterator parameter , we can set iterator parameter to True and after which the \n",
    "# read_csv will return same text parser object as it retuned above, and to get chunk values we will use get_chunk method and \n",
    "# need to pass chunksize after which it will return the chunked values.\n",
    "f1 = pd.read_csv('Data Sets\\Chunking_Data.csv',delimiter='|',iterator=True) # by default iterator is False\n",
    "print(f1)\n",
    "print(f1.get_chunk(3))\n",
    "print(f1.get_chunk(3))\n",
    "print(f1.get_chunk(3))\n",
    "print(f1.get_chunk(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Writing Data to Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  something  a   b     c   d message\n",
      "0       one  1   2   3.0   4     NaN\n",
      "1       two  5   6   NaN   8   world\n",
      "2     three  9  10  11.0  12     foo\n",
      "something,a,b,c,d,message\n",
      "one,1,2,3,4,NA\n",
      "two,5,6,,8,world\n",
      "three,9,10,11,12,foo\n",
      "\n",
      ",something,a,b,c,d,message\n",
      "0,one,1,2,3.0,4,\n",
      "1,two,5,6,,8,world\n",
      "2,three,9,10,11.0,12,foo\n",
      "\n",
      "|something|a|b|c|d|message\n",
      "0|one|1|2|3.0|4|\n",
      "1|two|5|6||8|world\n",
      "2|three|9|10|11.0|12|foo\n",
      "\n",
      ",something,a,b,c,d,message\n",
      "0,one,1,2,3.0,4,NULL\n",
      "1,two,5,6,NULL,8,world\n",
      "2,three,9,10,11.0,12,foo\n",
      "\n",
      "one,1,2,3.0,4,NULL\n",
      "two,5,6,NULL,8,world\n",
      "three,9,10,11.0,12,foo\n",
      "\n",
      "\n",
      "0   2020-08-16\n",
      "1   2020-08-17\n",
      "2   2020-08-18\n",
      "3   2020-08-19\n",
      "4   2020-08-20\n",
      "5   2020-08-21\n",
      "6   2020-08-22\n",
      "7   2020-08-23\n",
      "8   2020-08-24\n",
      "9   2020-08-25\n",
      "dtype: datetime64[ns]\n",
      ",0\n",
      "0,2020-08-16\n",
      "1,2020-08-17\n",
      "2,2020-08-18\n",
      "3,2020-08-19\n",
      "4,2020-08-20\n",
      "5,2020-08-21\n",
      "6,2020-08-22\n",
      "7,2020-08-23\n",
      "8,2020-08-24\n",
      "9,2020-08-25\n"
     ]
    }
   ],
   "source": [
    "# Data can also be exported to a delimited format. Let’s consider one of the CSV file read before:\n",
    "data = pd.read_csv('ex5.csv')\n",
    "print(data)\n",
    "!type ex5.csv\n",
    "\n",
    "# Using DataFrame’s to_csv method, we can write the data out to a comma-separated file:\n",
    "data.to_csv('firstw.csv') # here my var data has all the data stored of ex5.csv and i have used var data(which is now a DF) to \n",
    "print()\n",
    "# write into non-existing file named 'firstw.csv'.\n",
    "# print(pd.read_csv('firstw.csv'))\n",
    "!type firstw.csv\n",
    "\n",
    "# Other delimiters can be used, of course\n",
    "print()\n",
    "data.to_csv('secondw.csv',sep = '|')\n",
    "!type secondw.csv\n",
    "\n",
    "# Missing values appear as empty strings in the output. You might want to denote them by some other sentinel value:\n",
    "print()\n",
    "data.to_csv('thirdw.csv',na_rep = 'NULL' )\n",
    "!type thirdw.csv\n",
    "\n",
    "# With no other options specified, both the row and column labels are written. Both of these can be disabled:\n",
    "print()\n",
    "data.to_csv('fourthw.csv',na_rep = 'NULL' , index = False , header = False)\n",
    "!type fourthw.csv\n",
    "\n",
    "# You can also write only a subset of the columns, and in an order of your choosing:\n",
    "print()\n",
    "data.to_csv('fifthw.csv',na_rep = 'NULL' , index = False , columns = ['a','b','d'])\n",
    "\n",
    "# Series also has a to_csv method:\n",
    "print()\n",
    "dates = pd.date_range('16/08/2020',periods=10)\n",
    "dr = pd.Series(dates)\n",
    "print(dr)\n",
    "dr.to_csv('DateRange.csv') # in this way we can write our data into csv file and we can use dataframe as well.\n",
    "!type DateRange.csv \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Working with Delimited Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\",\"b\",\"c\"\n",
      "\n",
      "\"1\",\"2\",\"3\"\n",
      "\n",
      "\"1\",\"2\",\"3\"\n",
      "\n",
      "2,4,6\n",
      "\n",
      "8,10,12\n",
      "\n",
      "\n",
      "   a   b   c\n",
      "0  1   2   3\n",
      "1  1   2   3\n",
      "2  2   4   6\n",
      "3  8  10  12\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# It’s possible to load most forms of tabular data from disk using functions like pan\n",
    "# das.read_table. In some cases, however, some manual processing may be necessary.\n",
    "# It’s not uncommon to receive a file with one or more malformed lines that trip up\n",
    "# read_table. To illustrate the basic tools, consider a small CSV file:\n",
    "with open('ex6.csv') as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        \n",
    "# if i read this file using read_csv , this will convert string data to integer.\n",
    "print()\n",
    "f = pd.read_csv('ex6.csv')\n",
    "print(f)\n",
    "print(f.loc[1].dtype)\n",
    "\n",
    "# so if my data has multiple dtypes in it so using csv module is beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{'name': 'Wes', 'places_lived': ['United States', 'Spain', 'Germany'], 'pet': None, 'siblings': [{'name': 'Scott', 'age': 30, 'pets': ['Zeus', 'Zuko']}, {'name': 'Katie', 'age': 38, 'pets': ['Sixes', 'Stache', 'Cisco']}]} <class 'dict'>\n",
      "{\"name\": \"Wes\", \"places_lived\": [\"United States\", \"Spain\", \"Germany\"], \"pet\": null, \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]}, {\"name\": \"Katie\", \"age\": 38, \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]} <class 'str'>\n",
      "    name  age                    pets\n",
      "0  Scott   30            [Zeus, Zuko]\n",
      "1  Katie   38  [Sixes, Stache, Cisco]\n",
      "    name  age\n",
      "0  Scott   30\n",
      "1  Katie   38\n",
      "[{\"a\": 1, \"b\": 2, \"c\": 3},\n",
      "{\"a\": 4, \"b\": 5, \"c\": 6},\n",
      "{\"a\": 7, \"b\": 8, \"c\": 9}]\n",
      "   a  b  c\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "2  7  8  9\n"
     ]
    }
   ],
   "source": [
    "# JSON (short for JavaScript Object Notation) has become one of the standard formats\n",
    "# for sending data by HTTP request between web browsers and other applications. It is\n",
    "# a much more free-form data format than a tabular text form like CSV. Here is an example:\n",
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    " \"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n",
    " {\"name\": \"Katie\", \"age\": 38,\n",
    " \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n",
    "}\n",
    "\"\"\"\n",
    "print(type(obj)) # this will return str because the obj variable holds a dictionary.\n",
    "\n",
    "# JSON is very nearly valid Python code with the exception of its null value null and\n",
    "# some other nuances (such as disallowing trailing commas at the end of lists). The\n",
    "# basic types are objects (dicts), arrays (lists), strings, numbers, booleans, and nulls. All\n",
    "# of the keys in an object must be strings. There are several Python libraries for reading\n",
    "# and writing JSON data. I’ll use json here, as it is built into the Python standard\n",
    "# library. To convert a JSON string to Python form, use json.loads:\n",
    "import json\n",
    "result = json.loads(obj)\n",
    "print(result,type(result)) \n",
    "\n",
    "# json.dumps, on the other hand, converts a Python object back to JSON:\n",
    "asjson = json.dumps(result)\n",
    "print(asjson,type(asjson)) # type here is str again bc dump has converted the file.\n",
    "\n",
    "# How you convert a JSON object or list of objects to a DataFrame or some other data\n",
    "# structure for analysis will be up to you. Conveniently, you can pass a list of dicts\n",
    "# (which were previously JSON objects) to the DataFrame constructor and select a sub‐\n",
    "# set of the data fields:\n",
    "my_df = pd.DataFrame(result['siblings'])\n",
    "print(my_df)\n",
    "my_df = pd.DataFrame(result['siblings'],columns=['name','age'])\n",
    "print(my_df)\n",
    "\n",
    "# The pandas.read_json can automatically convert JSON datasets in specific arrange‐\n",
    "# ments into a Series or DataFrame. For example:\n",
    "!type first.json\n",
    "# The default options for pandas.read_json assume that each object in the JSON array is a row in the table:\n",
    "r = pd.read_json('first.json')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Binary Data Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the easiest ways to store data (also known as serialization) efficiently in binary\n",
    "# format is using Python’s built-in pickle serialization. pandas objects all have a\n",
    "# to_pickle method that writes the data to disk in pickle format.\n",
    "frame = pd.read_csv('ex1.csv')\n",
    "print(frame)\n",
    "\n",
    "frame.to_pickle('frame_pickle')\n",
    "# You can read any “pickled” object stored in a file by using the built-in pickle directly,\n",
    "# or even more conveniently using pandas.read_pickle:\n",
    "pd.read_pickle('frame_pickle')\n",
    "\n",
    "# pickle is only recommended as a short-term storage format. The\n",
    "# problem is that it is hard to guarantee that the format will be stable\n",
    "# over time; an object pickled today may not unpickle with a later\n",
    "# version of a library. We have tried to maintain backward compati‐\n",
    "# bility when possible, but at some point in the future it may be nec‐\n",
    "# essary to “break” the pickle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
